## Картинки для архитектуры и инструкции будут как сделаю дизайн(но текущая версия уже лежит)

## Цель проекта
Проект заключается в реализации модели из статьи [Ask me anything](https://arxiv.org/pdf/1506.07285.pdf), которая отвечает на заданный вопрос с учетом предшествующего контекста. В качестве примера использования модель обучается на датасете BABi-task, который содержит 20 типов различных вопросов определенной структуры. Данная задача является очень важной в настоящее время, так как модель, способная естественным образом отвечать на челоческие вопросы, способна быть хорошим интерфейсом для взаимодействия человека и машины.
## Известные решения
Авторы статьи сравнивают свои результаты с результатами других алгоритмов, использующих нейросети, например, [AMV-RNN](https://nlp.stanford.edu/pubs/SocherHuvalManningNg_EMNLP2012.pdf), [MemNN](https://arxiv.org/pdf/1503.08895.pdf) и [CT-LSTM](https://arxiv.org/pdf/1503.00075.pdf). Авторы статьи заявляют, что их решение обходит предыдущие.
## Архитектура модели
Архитектура нейросети повторяет, насколько у меня вышло, архитектуру, описанную в статье. Input module принимает на вход Glove-представления конктекста и выдает один последовательность векторов, характеризующую контекст. Question module делает то же самое, но на выходе получается один вектор - представление вопроса. Затем Memory module: используя представление вопроса для акцентирования внимания мы делаем проход по выходу Input module и получаем представление ответа, который затем раскодируем в 3 слова (максимальная длина ответа в Babi-task'е). Скрытые представления вопроса и слов конктекста имеют размер 80, слова на вход подаются как 50-ти мерные вектора обученной модели Glove, длину контекста ограничиваю 300 символами.
## Результаты
Модель из статьи, обученная на всех 20 типах вопросов одновременно, дает точность около 90%, что не очень высоко - учитывая, что модель, полученная в процессе работы над проектом, использующая в качестве Memory module простую GRU-сеть дает точность в 95% и намного проще обучается, но мой интерес заключался в реализации модели, предложенной авторами статьи.
Для визуализации работы модели была сделана web-страница с простым интерфейсом, которая по контексту и вопросу выводит предсказанный ответ.
## Выводы
Работа показывает, что достаточно простые типы вопросов с помощью новых алгоритмов, использующих нейросети, обрабатываются достаточно успешно - по крайней мере выден прогресс, и мы можем считать данный тип задач решенным. Будущий интерес состоит в решении более сложных и прикладных задач, и внедрении решений в повседневную жизнь. 
## Инструкция по установке
Для обучения нейронной сети вам понадобятся пакеты:
1) Keras 2.0, Tensorflow 1.0 - библиотеки для машинного обучения (вместе с зависимостями)
2) Keras_tqdm - альтернативная визуализация логов при обучении модели
3) Обученная модель glove (или любые другие модели векторного представления слов, но я использую именно glove)
4) Jupyter Notebook
Для того, чтобы обучить модель без изменений, откройте build_weights.ipynb, содержащий инструкции, с помощью Jupyter Notebook и просто запустите все ячейки
В итоге получите файлы vocabulary.pkl и weights.h5, используемые в следующей части
Для запуска приложения-сервера понадобятся:
1) Keras 2.0, Tensorflow 1.0
2) Flask - веб-сервер на python
3) Файлы vocabulary.pkl и weights.h5
Для запуска веб-сервера выполните python3 app.py
