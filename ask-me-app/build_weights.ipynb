{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2J"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Embedding, GRU, Dense\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import metrics, losses\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from subprocess import call\n",
    "call([\"jupyter\", \"nbextension\", \"enable\", \"--py\", \"--sys-prefix\", \"widgetsnbextension\"])\n",
    "%clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_file(tasks, fname):\n",
    "    task = None\n",
    "    for i, line in enumerate(open(fname)):\n",
    "        id = int(line[0:line.find(' ')])\n",
    "        if id == 1:\n",
    "            task = {\"C\": \"\", \"Q\": \"\", \"A\": \"\"} \n",
    "            \n",
    "        line = line.strip()\n",
    "        line = line.replace('.', ' . ')\n",
    "        line = line[line.find(' ')+1:]\n",
    "        if line.find('?') == -1:\n",
    "            task[\"C\"] += line\n",
    "        else:\n",
    "            idx = line.find('?')\n",
    "            tmp = line[idx+1:].split('\\t')\n",
    "            task[\"Q\"] = line[:idx]\n",
    "            task[\"A\"] = tmp[1].strip()\n",
    "            tasks.append(task.copy())\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set = []\n",
    "test_set = []\n",
    "for i in range(1, 21):\n",
    "    train_set_text = parse_file(train_set, \"tasks_1-20_v1-2/en-valid-10k/qa\" + str(i) + \"_train.txt\")\n",
    "    test_set_text = parse_file(test_set, \"tasks_1-20_v1-2/en-valid-10k/qa\" + str(i) + \"_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def glove_to_voc(fname):\n",
    "    voc = {}\n",
    "    with open(fname) as f:\n",
    "        for line in f:    \n",
    "            l = line.split()\n",
    "            voc[l[0]] = list(map(float, l[1:]))\n",
    "    return voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vector_size = 50\n",
    "vocabulary = {}\n",
    "vocabulary[\"PAD\"] = 0\n",
    "inv_vocabulary = {}\n",
    "inv_vocabulary[0] = \"PAD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glove = glove_to_voc(\"glove.6B.50d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_vector(word, glove, vocabulary, inv_vocabulary):\n",
    "    if not word in vocabulary: \n",
    "        next_index = len(vocabulary)\n",
    "        vocabulary[word] = next_index\n",
    "        inv_vocabulary[next_index] = word\n",
    "    \n",
    "    return vocabulary[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_input(text):\n",
    "        questions = []\n",
    "        inputs = []\n",
    "        answers = []\n",
    "        input_masks = []\n",
    "        for x in text:\n",
    "            inp = [w for w in x[\"C\"].lower().split(' ')  if len(w) > 0]\n",
    "            q = [w for w in x[\"Q\"].lower().split(' ') if len(w) > 0]\n",
    "            answ = [w for w in x[\"A\"].lower().split(',') if len(w) > 0]\n",
    "            \n",
    "            inp_vector = [get_word_vector(word = w, \n",
    "                                        glove = glove, \n",
    "                                        vocabulary = vocabulary, \n",
    "                                        inv_vocabulary = inv_vocabulary) for w in inp]\n",
    "              \n",
    "            inputs.append(np.vstack(inp_vector))\n",
    "            \n",
    "            q_vector = [get_word_vector(word = w,\n",
    "                                        glove = glove, \n",
    "                                        vocabulary = vocabulary, \n",
    "                                        inv_vocabulary = inv_vocabulary) for w in q]\n",
    "            \n",
    "            questions.append(np.vstack(q_vector))\n",
    "            \n",
    "\n",
    "            ans_vector = [get_word_vector(word = w,\n",
    "                                            glove = glove, \n",
    "                                            vocabulary = vocabulary, \n",
    "                                            inv_vocabulary = inv_vocabulary) for w in answ]\n",
    "\n",
    "            while(len(ans_vector) < 3):\n",
    "                ans_vector.append(0)\n",
    "            answers.append(np.vstack(ans_vector))\n",
    "            \n",
    "            input_masks.append(np.array([index for index, w in enumerate(inp) if w == '.'], dtype=np.int32)) \n",
    "        return inputs, questions, answers, input_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_c_len = 300\n",
    "max_q_len = 7\n",
    "hidden_size = 84\n",
    "max_ans_len = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "context, questions, answers, masks = process_input(train_set_text)\n",
    "val_context, val_questions, val_answers, val_masks = process_input(test_set_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_mat(answers, len1, len2):\n",
    "    mt = np.zeros((len(answers), len1, len2))\n",
    "    for i in range(len(answers)):\n",
    "        for j in range(len1):\n",
    "            mt[i][j][answers[i][j]] = 1\n",
    "    return mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcontext = pad_sequences(context, maxlen=max_c_len, dtype='int32', padding='post', truncating='post', value=0)\n",
    "pcontext = pcontext.reshape(pcontext.shape[:2])\n",
    "pquestions = pad_sequences(questions, maxlen=max_q_len, dtype='int32', padding='post', truncating='post', value=0)\n",
    "pquestions = pquestions.reshape(pquestions.shape[:2])\n",
    "ans_mat = make_mat(answers, max_ans_len, len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_pquestions = pad_sequences(val_questions, maxlen=max_q_len, dtype='int32', padding='post', truncating='post', value=0)\n",
    "val_pquestions = val_pquestions.reshape(val_pquestions.shape[:2])\n",
    "val_pcontext = pad_sequences(val_context, maxlen=max_c_len, dtype='int32', padding='post', truncating='post', value=0)\n",
    "val_pcontext = val_pcontext.reshape(val_pcontext.shape[:2])\n",
    "val_ans_mat = make_mat(val_answers, 3, len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(vocabulary), 50))\n",
    "for word in vocabulary.keys():\n",
    "    if not word in glove:\n",
    "        glove[word] = np.random.uniform(0.0,1.0,(word_vector_size,))\n",
    "    embedding_matrix[vocabulary[word]] = glove[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gru_inh import myGru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_categorical_accuracy(y_true, y_pred):\n",
    "    return K.min(K.cast(K.equal(K.argmax(y_true, axis=-1),\n",
    "                          K.argmax(y_pred, axis=-1)),\n",
    "                  K.floatx()), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#input module\n",
    "\n",
    "context_input = Input(shape=(max_c_len,), dtype='int32', name='context_input')\n",
    "\n",
    "embedded_context = Embedding(input_dim = len(vocabulary),\n",
    "                            output_dim = 50,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_c_len,\n",
    "                            mask_zero = True,\n",
    "                            trainable=False) (context_input)\n",
    "\n",
    "facts = GRU(units=hidden_size, return_sequences=True) (embedded_context)\n",
    "\n",
    "# question module\n",
    "\n",
    "question_input = Input(shape=(max_q_len,), dtype='int32', name='question_input')\n",
    "\n",
    "embedded_question= Embedding(input_dim = len(vocabulary),\n",
    "                            output_dim = 50,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_q_len,\n",
    "                            mask_zero = True,\n",
    "                            trainable=False) (question_input)\n",
    "\n",
    "question_rep = GRU(units=hidden_size) (embedded_question)\n",
    "\n",
    "many_quests = keras.layers.core.RepeatVector(max_c_len) (question_rep)\n",
    "\n",
    "# episodic memory module\n",
    "\n",
    "concated = keras.layers.concatenate([facts, many_quests])\n",
    "memory = myGru(units=hidden_size, implementation = 1) (concated)\n",
    "\n",
    "# answer module\n",
    "\n",
    "three_memories = keras.layers.RepeatVector(3) (memory)\n",
    "to_answer = GRU(units=hidden_size, return_sequences=True) (three_memories)\n",
    "net_output = keras.layers.TimeDistributed(Dense(units=len(vocabulary), activation=\"softmax\")) (to_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[context_input, question_input], outputs=[net_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss=losses.categorical_crossentropy,\n",
    "              metrics=[metrics.categorical_accuracy,\n",
    "                      custom_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"629pt\" viewBox=\"0.00 0.00 347.00 629.00\" width=\"347pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 625)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-625 343,-625 343,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140142309045752 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140142309045752</title>\n",
       "<polygon fill=\"none\" points=\"0,-584.5 0,-620.5 164,-620.5 164,-584.5 0,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"82\" y=\"-598.8\">question_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140142243192784 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140142243192784</title>\n",
       "<polygon fill=\"none\" points=\"1.5,-511.5 1.5,-547.5 162.5,-547.5 162.5,-511.5 1.5,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"82\" y=\"-525.8\">embedding_2: Embedding</text>\n",
       "</g>\n",
       "<!-- 140142309045752&#45;&gt;140142243192784 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140142309045752-&gt;140142243192784</title>\n",
       "<path d=\"M82,-584.313C82,-576.289 82,-566.547 82,-557.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"85.5001,-557.529 82,-547.529 78.5001,-557.529 85.5001,-557.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140142309045528 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140142309045528</title>\n",
       "<polygon fill=\"none\" points=\"181,-511.5 181,-547.5 339,-547.5 339,-511.5 181,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"260\" y=\"-525.8\">context_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140142309046536 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140142309046536</title>\n",
       "<polygon fill=\"none\" points=\"177.5,-438.5 177.5,-474.5 338.5,-474.5 338.5,-438.5 177.5,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258\" y=\"-452.8\">embedding_1: Embedding</text>\n",
       "</g>\n",
       "<!-- 140142309045528&#45;&gt;140142309046536 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140142309045528-&gt;140142309046536</title>\n",
       "<path d=\"M259.516,-511.313C259.29,-503.289 259.015,-493.547 258.763,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"262.26,-484.426 258.48,-474.529 255.263,-484.623 262.26,-484.426\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140142305885208 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140142305885208</title>\n",
       "<polygon fill=\"none\" points=\"53,-438.5 53,-474.5 137,-474.5 137,-438.5 53,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"95\" y=\"-452.8\">gru_2: GRU</text>\n",
       "</g>\n",
       "<!-- 140142243192784&#45;&gt;140142305885208 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140142243192784-&gt;140142305885208</title>\n",
       "<path d=\"M85.1469,-511.313C86.616,-503.289 88.3998,-493.547 90.0437,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"93.5237,-484.996 91.882,-474.529 86.6382,-483.735 93.5237,-484.996\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140142309046816 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140142309046816</title>\n",
       "<polygon fill=\"none\" points=\"214,-365.5 214,-401.5 298,-401.5 298,-365.5 214,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256\" y=\"-379.8\">gru_1: GRU</text>\n",
       "</g>\n",
       "<!-- 140142309046536&#45;&gt;140142309046816 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140142309046536-&gt;140142309046816</title>\n",
       "<path d=\"M257.516,-438.313C257.29,-430.289 257.015,-420.547 256.763,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"260.26,-411.426 256.48,-401.529 253.263,-411.623 260.26,-411.426\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140141226993088 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140141226993088</title>\n",
       "<polygon fill=\"none\" points=\"8.5,-365.5 8.5,-401.5 193.5,-401.5 193.5,-365.5 8.5,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101\" y=\"-379.8\">repeat_vector_1: RepeatVector</text>\n",
       "</g>\n",
       "<!-- 140142305885208&#45;&gt;140141226993088 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140142305885208-&gt;140141226993088</title>\n",
       "<path d=\"M96.4524,-438.313C97.1305,-430.289 97.9537,-420.547 98.7125,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"102.206,-411.788 99.5609,-401.529 95.2312,-411.199 102.206,-411.788\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140141141282040 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140141141282040</title>\n",
       "<polygon fill=\"none\" points=\"94,-292.5 94,-328.5 262,-328.5 262,-292.5 94,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178\" y=\"-306.8\">concatenate_1: Concatenate</text>\n",
       "</g>\n",
       "<!-- 140142309046816&#45;&gt;140141141282040 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140142309046816-&gt;140141141282040</title>\n",
       "<path d=\"M237.118,-365.313C227.25,-356.33 215.015,-345.193 204.241,-335.386\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"206.459,-332.672 196.708,-328.529 201.747,-337.849 206.459,-332.672\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140141226993088&#45;&gt;140141141282040 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140141226993088-&gt;140141141282040</title>\n",
       "<path d=\"M119.64,-365.313C129.381,-356.33 141.459,-345.193 152.096,-335.386\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"154.553,-337.881 159.532,-328.529 149.808,-332.735 154.553,-337.881\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140141142009336 -->\n",
       "<g class=\"node\" id=\"node9\"><title>140141142009336</title>\n",
       "<polygon fill=\"none\" points=\"118.5,-219.5 118.5,-255.5 237.5,-255.5 237.5,-219.5 118.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178\" y=\"-233.8\">my_gru_1: myGru</text>\n",
       "</g>\n",
       "<!-- 140141141282040&#45;&gt;140141142009336 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>140141141282040-&gt;140141142009336</title>\n",
       "<path d=\"M178,-292.313C178,-284.289 178,-274.547 178,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"181.5,-265.529 178,-255.529 174.5,-265.529 181.5,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140141142009056 -->\n",
       "<g class=\"node\" id=\"node10\"><title>140141142009056</title>\n",
       "<polygon fill=\"none\" points=\"85.5,-146.5 85.5,-182.5 270.5,-182.5 270.5,-146.5 85.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178\" y=\"-160.8\">repeat_vector_2: RepeatVector</text>\n",
       "</g>\n",
       "<!-- 140141142009336&#45;&gt;140141142009056 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>140141142009336-&gt;140141142009056</title>\n",
       "<path d=\"M178,-219.313C178,-211.289 178,-201.547 178,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"181.5,-192.529 178,-182.529 174.5,-192.529 181.5,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140141140384848 -->\n",
       "<g class=\"node\" id=\"node11\"><title>140141140384848</title>\n",
       "<polygon fill=\"none\" points=\"136,-73.5 136,-109.5 220,-109.5 220,-73.5 136,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178\" y=\"-87.8\">gru_3: GRU</text>\n",
       "</g>\n",
       "<!-- 140141142009056&#45;&gt;140141140384848 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>140141142009056-&gt;140141140384848</title>\n",
       "<path d=\"M178,-146.313C178,-138.289 178,-128.547 178,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"181.5,-119.529 178,-109.529 174.5,-119.529 181.5,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140141101542872 -->\n",
       "<g class=\"node\" id=\"node12\"><title>140141101542872</title>\n",
       "<polygon fill=\"none\" points=\"21.5,-0.5 21.5,-36.5 334.5,-36.5 334.5,-0.5 21.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178\" y=\"-14.8\">time_distributed_1(dense_1): TimeDistributed(Dense)</text>\n",
       "</g>\n",
       "<!-- 140141140384848&#45;&gt;140141101542872 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>140141140384848-&gt;140141101542872</title>\n",
       "<path d=\"M178,-73.3129C178,-65.2895 178,-55.5475 178,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"181.5,-46.5288 178,-36.5288 174.5,-46.5289 181.5,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          179968/|/[loss: 0.113, categorical_accuracy: 0.943, custom_categorical_accuracy: 0.857] 100%|| 179968/179998 [2:48:10<00:01, 18.06it/s]179968/|/[loss: 0.107, categorical_accuracy: 0.946, custom_categorical_accuracy: 0.868] 100%|| 179968/179998 [2:50:12<00:01, 17.94it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f74e47bb198>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([pcontext, pquestions], ans_mat,epochs=2, verbose=0, \n",
    "          callbacks=[TQDMNotebookCallback(leave_inner=True, leave_outer=True)],\n",
    "          validation_data=([val_pcontext, val_pquestions], val_ans_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('vocabulary.pkl', 'wb') as f:\n",
    "        pickle.dump(vocabulary, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_voc = {}\n",
    "with open('vocabulary.pkl', 'rb') as f:\n",
    "        new_voc = pickle.load(f)\n",
    "new_inv_voc = {v: k for k, v in new_voc.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_answer(model, vocabulary, inv_vocabulary, context, question):\n",
    "    context = context.replace('.', ' . ')\n",
    "    inp = [w for w in context.lower().split(' ')  if len(w) > 0]\n",
    "    if '?' in question:\n",
    "        question = question[:question.find('?')]\n",
    "    q = [w for w in question.lower().split(' ') if len(w) > 0]\n",
    "    inp_vector = [vocabulary[w] for w in inp]\n",
    "    quest_vector = [vocabulary[w] for w in q]\n",
    "    cur_context = pad_sequences([inp_vector], maxlen=max_c_len, dtype='int32',\n",
    "                      padding='post', truncating='post', value=0)\n",
    "    cur_question = pad_sequences([quest_vector], maxlen=max_q_len, dtype='int32',\n",
    "                      padding='post', truncating='post', value=0)\n",
    "    prediction = model.predict([cur_context, cur_question])\n",
    "    answer = []\n",
    "    for i in range(max_ans_len):\n",
    "        cur_word = np.argmax(prediction[0][i])\n",
    "        if cur_word == 0:\n",
    "            break\n",
    "        answer.append(inv_vocabulary[cur_word])\n",
    "    return ', '.join(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kitchen\n"
     ]
    }
   ],
   "source": [
    "print(get_answer(model, new_voc, new_inv_voc, 'John travelled to the garden. John journeyed to the kitchen.', 'Where is John?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "0a9af9bc2d2f4e61a6dba69da29d8107": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "441d5226879e46898a8ecb162772fafa": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "61b9346a8f2340f781fb348d51ea1f58": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "61db1af8d067420d8f85a595f5f4c479": {
     "views": [
      {
       "cell_index": 21
      }
     ]
    },
    "6db2614f83ae44e4bc0f1cd697154de4": {
     "views": [
      {
       "cell_index": 21
      }
     ]
    },
    "8de1aeb342804eaaa89bf17be0c9e008": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "a9cb149749b74ea0a6f59af2c075287e": {
     "views": [
      {
       "cell_index": 21
      }
     ]
    },
    "d930ba9ae1334b22b424497e220487fc": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "e55eaef5c80549d1b16ee8d53f0d5be5": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "eab66e15100d409192355c9ad8cf17fd": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
