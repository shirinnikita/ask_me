{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2J"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Embedding, GRU, Dense\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import metrics, losses\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from subprocess import call\n",
    "call([\"jupyter\", \"nbextension\", \"enable\", \"--py\", \"--sys-prefix\", \"widgetsnbextension\"])\n",
    "%clear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем функцию, извлекающую из baBi task файла триплеты C(context)-Q(question)-A(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_file(tasks, fname):\n",
    "    task = None\n",
    "    for i, line in enumerate(open(fname)):\n",
    "        id = int(line[0:line.find(' ')])\n",
    "        if id == 1:\n",
    "            task = {\"C\": \"\", \"Q\": \"\", \"A\": \"\"} \n",
    "            \n",
    "        line = line.strip()\n",
    "        line = line.replace('.', ' . ')\n",
    "        line = line[line.find(' ')+1:]\n",
    "        if line.find('?') == -1:\n",
    "            task[\"C\"] += line\n",
    "        else:\n",
    "            idx = line.find('?')\n",
    "            tmp = line[idx+1:].split('\\t')\n",
    "            task[\"Q\"] = line[:idx]\n",
    "            task[\"A\"] = tmp[1].strip()\n",
    "            tasks.append(task.copy())\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Парсим все 20 заданий, формируя обучающую и тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set = []\n",
    "test_set = []\n",
    "for i in range(1, 21):\n",
    "    train_set_text = parse_file(train_set, \"tasks_1-20_v1-2/en-valid-10k/qa\" + str(i) + \"_train.txt\")\n",
    "    test_set_text = parse_file(test_set, \"tasks_1-20_v1-2/en-valid-10k/qa\" + str(i) + \"_test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем функцию, загружающую в память вектора слов из GloVe-файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def glove_to_voc(fname):\n",
    "    voc = {}\n",
    "    with open(fname) as f:\n",
    "        for line in f:    \n",
    "            l = line.split()\n",
    "            voc[l[0]] = list(map(float, l[1:]))\n",
    "    return voc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем размер векторных представлений слов и добавляем специальное PAD-слово (им буду дополняться ответы до длины 3 - максимальной в bAbi tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vector_size = 50\n",
    "vocabulary = {}\n",
    "vocabulary[\"PAD\"] = 0\n",
    "inv_vocabulary = {}\n",
    "inv_vocabulary[0] = \"PAD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glove = glove_to_voc(\"glove.6B.50d.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, добавляющая слова в словари"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_index(word, vocabulary, inv_vocabulary):\n",
    "    if not word in vocabulary: \n",
    "        next_index = len(vocabulary)\n",
    "        vocabulary[word] = next_index\n",
    "        inv_vocabulary[next_index] = word\n",
    "    \n",
    "    return vocabulary[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, превращающая триплеты в вектора (предложению будут соответствовать последовательность индексов слов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_input(text):\n",
    "        questions = []\n",
    "        inputs = []\n",
    "        answers = []\n",
    "        input_masks = []\n",
    "        for x in text:\n",
    "            inp = [w for w in x[\"C\"].lower().split(' ')  if len(w) > 0]\n",
    "            q = [w for w in x[\"Q\"].lower().split(' ') if len(w) > 0]\n",
    "            answ = [w for w in x[\"A\"].lower().split(',') if len(w) > 0]\n",
    "            \n",
    "            inp_vector = [get_index(word = w, \n",
    "                                        vocabulary = vocabulary, \n",
    "                                        inv_vocabulary = inv_vocabulary) for w in inp]\n",
    "              \n",
    "            inputs.append(np.vstack(inp_vector))\n",
    "            \n",
    "            q_vector = [get_index(word = w,\n",
    "                                        vocabulary = vocabulary, \n",
    "                                        inv_vocabulary = inv_vocabulary) for w in q]\n",
    "            \n",
    "            questions.append(np.vstack(q_vector))\n",
    "            \n",
    "\n",
    "            ans_vector = [get_index(word = w, \n",
    "                                            vocabulary = vocabulary, \n",
    "                                            inv_vocabulary = inv_vocabulary) for w in answ]\n",
    "\n",
    "            while(len(ans_vector) < 3):\n",
    "                ans_vector.append(0)\n",
    "            answers.append(np.vstack(ans_vector))\n",
    "            \n",
    "            input_masks.append(np.array([index for index, w in enumerate(inp) if w == '.'], dtype=np.int32)) \n",
    "        return inputs, questions, answers, input_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_c_len = 300 # максимальная длина контекста\n",
    "max_q_len = 7 # максимальная длина вопроса\n",
    "hidden_size = 84 # размер векторов в нейросети - представлений вопроса и контекста\n",
    "max_ans_len = 3 # максимальная длина ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "context, questions, answers, masks = process_input(train_set_text)\n",
    "val_context, val_questions, val_answers, val_masks = process_input(test_set_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, создающая матрицу правильных ответов (labels для нейросети)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_mat(answers, len1, len2):\n",
    "    mt = np.zeros((len(answers), len1, len2))\n",
    "    for i in range(len(answers)):\n",
    "        for j in range(len1):\n",
    "            mt[i][j][answers[i][j]] = 1\n",
    "    return mt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем данные подходящего для нейросети вида - *pad_sequences* обрезает/дополняет предложения до заданной длины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcontext = pad_sequences(context, maxlen=max_c_len, dtype='int32', padding='post', truncating='post', value=0)\n",
    "pcontext = pcontext.reshape(pcontext.shape[:2])\n",
    "pquestions = pad_sequences(questions, maxlen=max_q_len, dtype='int32', padding='post', truncating='post', value=0)\n",
    "pquestions = pquestions.reshape(pquestions.shape[:2])\n",
    "ans_mat = make_mat(answers, max_ans_len, len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_pquestions = pad_sequences(val_questions, maxlen=max_q_len, dtype='int32', padding='post', truncating='post', value=0)\n",
    "val_pquestions = val_pquestions.reshape(val_pquestions.shape[:2])\n",
    "val_pcontext = pad_sequences(val_context, maxlen=max_c_len, dtype='int32', padding='post', truncating='post', value=0)\n",
    "val_pcontext = val_pcontext.reshape(val_pcontext.shape[:2])\n",
    "val_ans_mat = make_mat(val_answers, 3, len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем матрицу представлений слов, т.е. при умножении one-hot закодированных слов на эту матрицу получается векторное представление слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(vocabulary), 50))\n",
    "for word in vocabulary.keys():\n",
    "    if not word in glove:\n",
    "        glove[word] = np.random.uniform(0.0,1.0,(word_vector_size,))\n",
    "    embedding_matrix[vocabulary[word]] = glove[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем написанный отдельно слой, чтобы архитектура сети соответствовала описанной в статье"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gru_inh import myGru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика, показывающая долю полностью правильных ответов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_categorical_accuracy(y_true, y_pred):\n",
    "    return K.min(K.cast(K.equal(K.argmax(y_true, axis=-1),\n",
    "                          K.argmax(y_pred, axis=-1)),\n",
    "                  K.floatx()), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сама нейросеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#input module\n",
    "\n",
    "context_input = Input(shape=(max_c_len,), dtype='int32', name='context_input')\n",
    "\n",
    "embedded_context = Embedding(input_dim = len(vocabulary),\n",
    "                            output_dim = 50,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_c_len,\n",
    "                            mask_zero = True,\n",
    "                            trainable=False) (context_input)\n",
    "\n",
    "facts = GRU(units=hidden_size, return_sequences=True) (embedded_context)\n",
    "\n",
    "# question module\n",
    "\n",
    "question_input = Input(shape=(max_q_len,), dtype='int32', name='question_input')\n",
    "\n",
    "embedded_question= Embedding(input_dim = len(vocabulary),\n",
    "                            output_dim = 50,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_q_len,\n",
    "                            mask_zero = True,\n",
    "                            trainable=False) (question_input)\n",
    "\n",
    "question_rep = GRU(units=hidden_size) (embedded_question)\n",
    "\n",
    "many_quests = keras.layers.core.RepeatVector(max_c_len) (question_rep)\n",
    "\n",
    "# episodic memory module\n",
    "\n",
    "concated = keras.layers.concatenate([facts, many_quests])\n",
    "# memory = myGru(units=hidden_size, implementation = 1) (concated)\n",
    "memory = GRU(units=hidden_size) (concated)\n",
    "# answer module\n",
    "\n",
    "three_memories = keras.layers.RepeatVector(3) (memory)\n",
    "to_answer = GRU(units=hidden_size, return_sequences=True) (three_memories)\n",
    "net_output = keras.layers.TimeDistributed(Dense(units=len(vocabulary), activation=\"softmax\")) (to_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[context_input, question_input], outputs=[net_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss=losses.categorical_crossentropy,\n",
    "              metrics=[metrics.categorical_accuracy,\n",
    "                      custom_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно визуализировать архитектуру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"629pt\" viewBox=\"0.00 0.00 347.00 629.00\" width=\"347pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 625)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-625 343,-625 343,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140413429460720 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140413429460720</title>\n",
       "<polygon fill=\"none\" points=\"0,-584.5 0,-620.5 164,-620.5 164,-584.5 0,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"82\" y=\"-598.8\">question_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140413429775944 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140413429775944</title>\n",
       "<polygon fill=\"none\" points=\"1.5,-511.5 1.5,-547.5 162.5,-547.5 162.5,-511.5 1.5,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"82\" y=\"-525.8\">embedding_2: Embedding</text>\n",
       "</g>\n",
       "<!-- 140413429460720&#45;&gt;140413429775944 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140413429460720-&gt;140413429775944</title>\n",
       "<path d=\"M82,-584.313C82,-576.289 82,-566.547 82,-557.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"85.5001,-557.529 82,-547.529 78.5001,-557.529 85.5001,-557.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140413429460664 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140413429460664</title>\n",
       "<polygon fill=\"none\" points=\"181,-511.5 181,-547.5 339,-547.5 339,-511.5 181,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"260\" y=\"-525.8\">context_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140414304322280 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140414304322280</title>\n",
       "<polygon fill=\"none\" points=\"177.5,-438.5 177.5,-474.5 338.5,-474.5 338.5,-438.5 177.5,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258\" y=\"-452.8\">embedding_1: Embedding</text>\n",
       "</g>\n",
       "<!-- 140413429460664&#45;&gt;140414304322280 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140413429460664-&gt;140414304322280</title>\n",
       "<path d=\"M259.516,-511.313C259.29,-503.289 259.015,-493.547 258.763,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"262.26,-484.426 258.48,-474.529 255.263,-484.623 262.26,-484.426\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140414304321608 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140414304321608</title>\n",
       "<polygon fill=\"none\" points=\"53,-438.5 53,-474.5 137,-474.5 137,-438.5 53,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"95\" y=\"-452.8\">gru_2: GRU</text>\n",
       "</g>\n",
       "<!-- 140413429775944&#45;&gt;140414304321608 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140413429775944-&gt;140414304321608</title>\n",
       "<path d=\"M85.1469,-511.313C86.616,-503.289 88.3998,-493.547 90.0437,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"93.5237,-484.996 91.882,-474.529 86.6382,-483.735 93.5237,-484.996\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140413429705696 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140413429705696</title>\n",
       "<polygon fill=\"none\" points=\"214,-365.5 214,-401.5 298,-401.5 298,-365.5 214,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256\" y=\"-379.8\">gru_1: GRU</text>\n",
       "</g>\n",
       "<!-- 140414304322280&#45;&gt;140413429705696 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140414304322280-&gt;140413429705696</title>\n",
       "<path d=\"M257.516,-438.313C257.29,-430.289 257.015,-420.547 256.763,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"260.26,-411.426 256.48,-401.529 253.263,-411.623 260.26,-411.426\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140413385758592 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140413385758592</title>\n",
       "<polygon fill=\"none\" points=\"8.5,-365.5 8.5,-401.5 193.5,-401.5 193.5,-365.5 8.5,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101\" y=\"-379.8\">repeat_vector_1: RepeatVector</text>\n",
       "</g>\n",
       "<!-- 140414304321608&#45;&gt;140413385758592 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140414304321608-&gt;140413385758592</title>\n",
       "<path d=\"M96.4524,-438.313C97.1305,-430.289 97.9537,-420.547 98.7125,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"102.206,-411.788 99.5609,-401.529 95.2312,-411.199 102.206,-411.788\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140413386276424 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140413386276424</title>\n",
       "<polygon fill=\"none\" points=\"94,-292.5 94,-328.5 262,-328.5 262,-292.5 94,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178\" y=\"-306.8\">concatenate_1: Concatenate</text>\n",
       "</g>\n",
       "<!-- 140413429705696&#45;&gt;140413386276424 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140413429705696-&gt;140413386276424</title>\n",
       "<path d=\"M237.118,-365.313C227.25,-356.33 215.015,-345.193 204.241,-335.386\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"206.459,-332.672 196.708,-328.529 201.747,-337.849 206.459,-332.672\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140413385758592&#45;&gt;140413386276424 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140413385758592-&gt;140413386276424</title>\n",
       "<path d=\"M119.64,-365.313C129.381,-356.33 141.459,-345.193 152.096,-335.386\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"154.553,-337.881 159.532,-328.529 149.808,-332.735 154.553,-337.881\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140413386275976 -->\n",
       "<g class=\"node\" id=\"node9\"><title>140413386275976</title>\n",
       "<polygon fill=\"none\" points=\"118.5,-219.5 118.5,-255.5 237.5,-255.5 237.5,-219.5 118.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178\" y=\"-233.8\">my_gru_1: myGru</text>\n",
       "</g>\n",
       "<!-- 140413386276424&#45;&gt;140413386275976 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>140413386276424-&gt;140413386275976</title>\n",
       "<path d=\"M178,-292.313C178,-284.289 178,-274.547 178,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"181.5,-265.529 178,-255.529 174.5,-265.529 181.5,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140413384046464 -->\n",
       "<g class=\"node\" id=\"node10\"><title>140413384046464</title>\n",
       "<polygon fill=\"none\" points=\"85.5,-146.5 85.5,-182.5 270.5,-182.5 270.5,-146.5 85.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178\" y=\"-160.8\">repeat_vector_2: RepeatVector</text>\n",
       "</g>\n",
       "<!-- 140413386275976&#45;&gt;140413384046464 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>140413386275976-&gt;140413384046464</title>\n",
       "<path d=\"M178,-219.313C178,-211.289 178,-201.547 178,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"181.5,-192.529 178,-182.529 174.5,-192.529 181.5,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140413383591696 -->\n",
       "<g class=\"node\" id=\"node11\"><title>140413383591696</title>\n",
       "<polygon fill=\"none\" points=\"136,-73.5 136,-109.5 220,-109.5 220,-73.5 136,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178\" y=\"-87.8\">gru_3: GRU</text>\n",
       "</g>\n",
       "<!-- 140413384046464&#45;&gt;140413383591696 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>140413384046464-&gt;140413383591696</title>\n",
       "<path d=\"M178,-146.313C178,-138.289 178,-128.547 178,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"181.5,-119.529 178,-109.529 174.5,-119.529 181.5,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140413429460496 -->\n",
       "<g class=\"node\" id=\"node12\"><title>140413429460496</title>\n",
       "<polygon fill=\"none\" points=\"21.5,-0.5 21.5,-36.5 334.5,-36.5 334.5,-0.5 21.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178\" y=\"-14.8\">time_distributed_1(dense_1): TimeDistributed(Dense)</text>\n",
       "</g>\n",
       "<!-- 140413383591696&#45;&gt;140413429460496 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>140413383591696-&gt;140413429460496</title>\n",
       "<path d=\"M178,-73.3129C178,-65.2895 178,-55.5475 178,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"181.5,-46.5288 178,-36.5288 174.5,-46.5289 181.5,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit([pcontext, pquestions], ans_mat,epochs=10, verbose=0, \n",
    "          callbacks=[TQDMNotebookCallback(leave_inner=True, leave_outer=True)],\n",
    "          validation_data=([val_pcontext, val_pquestions], val_ans_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем веса и словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "          \r",
      "171072/|/[loss: 0.103, categorical_accuracy: 0.948, custom_categorical_accuracy: 0.871]  95%|| 171072/179998 [2:05:16<06:30, 22.85it/s]"
     ]
    }
   ],
   "source": [
    "model.save(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('vocabulary.pkl', 'wb') as f:\n",
    "        pickle.dump(vocabulary, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем работоспособность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = load_model(\"weights.h5\", custom_objects={'myGru':myGru,\n",
    "        'custom_categorical_accuracy':custom_categorical_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_voc = {}\n",
    "with open('vocabulary.pkl', 'rb') as f:\n",
    "        new_voc = pickle.load(f)\n",
    "new_inv_voc = {v: k for k, v in new_voc.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, которая отвечает за запросы на сервер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_answer(model, vocabulary, inv_vocabulary, context, question):\n",
    "    context = context.replace('.', ' . ')\n",
    "    inp = [w for w in context.lower().split(' ')  if len(w) > 0]\n",
    "    if '?' in question:\n",
    "        question = question[:question.find('?')]\n",
    "    q = [w for w in question.lower().split(' ') if len(w) > 0]\n",
    "    inp_vector = [vocabulary[w] for w in inp]\n",
    "    quest_vector = [vocabulary[w] for w in q]\n",
    "    cur_context = pad_sequences([inp_vector], maxlen=max_c_len, dtype='int32',\n",
    "                      padding='post', truncating='post', value=0)\n",
    "    cur_question = pad_sequences([quest_vector], maxlen=max_q_len, dtype='int32',\n",
    "                      padding='post', truncating='post', value=0)\n",
    "    prediction = model.predict([cur_context, cur_question])\n",
    "    answer = []\n",
    "    for i in range(max_ans_len):\n",
    "        cur_word = np.argmax(prediction[0][i])\n",
    "        if cur_word == 0:\n",
    "            break\n",
    "        answer.append(inv_vocabulary[cur_word])\n",
    "    return ', '.join(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kitchen\n"
     ]
    }
   ],
   "source": [
    "print(get_answer(model, new_voc, new_inv_voc, 'John travelled to the garden. John journeyed to the kitchen.', 'Where is John?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
